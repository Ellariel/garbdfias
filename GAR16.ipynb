{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEIhmQhJvgie"
   },
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xqrFsf5nvmB_"
   },
   "outputs": [],
   "source": [
    "!pip install numpy==1.21.4\n",
    "!pip install pandas==1.3.4\n",
    "!pip install loguru==0.5.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipX-FF3avuts"
   },
   "source": [
    "# Mount Clone Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tVd6ywt5rix0"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\", force_remount=True)\n",
    "# replace with your path\n",
    "%cd \"drive/MyDrive/gar_colab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zcm8fEnfq8xi"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/nurtdinovadf/garbdfias.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6cy5G9a8rEHO"
   },
   "outputs": [],
   "source": [
    "%cd garbdfias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lq9VxcMyuWRf"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7jter17duXh3"
   },
   "outputs": [],
   "source": [
    "!tar -xvf data.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vdwkbIJ-ubUR"
   },
   "outputs": [],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvLIalZPwJdk"
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VYyy6Cb3ulm2"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYGztaFZwRw4"
   },
   "source": [
    "# Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hm21ALATwO6Q"
   },
   "outputs": [],
   "source": [
    "def cleanup(x):\n",
    "    \"\"\"\n",
    "    Manual object cleaning\n",
    "    \"\"\"\n",
    "    del x\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "def parse_xml(x):\n",
    "    \"\"\"\n",
    "    Parse GAR XML file into pandas dataframe object\n",
    "    \"\"\"\n",
    "    tree = ET.parse(x)\n",
    "    root = tree.getroot()\n",
    "    df = [child.attrib for child in root]\n",
    "    df = pd.DataFrame.from_dict(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_adms(df):\n",
    "    \"\"\"\n",
    "    Get administrative \"object-parent\" relations into dictionary for later use\n",
    "    \"\"\"\n",
    "    rftree = df[['OBJECTID', 'PARENTOBJID']].groupby(\n",
    "        by='OBJECTID'\n",
    "    )['PARENTOBJID'].apply(list).to_dict()\n",
    "    return rftree\n",
    "\n",
    "\n",
    "def get_adms_rec_rev(chain, rdadm):\n",
    "    \"\"\"\n",
    "    Get administrative address chains recursively\n",
    "    \"\"\"\n",
    "    objid = chain[-1]\n",
    "    if objid in rdadm and objid == objid:\n",
    "        chains = [chain + [obj] for obj in rdadm[objid] if obj == obj]\n",
    "        return [\n",
    "            get_adms_rec_rev(ch, rdadm) for ch in chains\n",
    "        ] if len(chains) > 1 else get_adms_rec_rev(chains[0], rdadm)\n",
    "    return chain\n",
    "\n",
    "\n",
    "def get_town(x):\n",
    "    \"\"\"\n",
    "    Chain post-cleanup.\n",
    "    \"\"\"\n",
    "    priority = ['5', '6', '4', '7', '1']\n",
    "    street = [f'{i}' for i in range(8, 0, -1)]\n",
    "    streets = [p for p in street if x[p] == 1]\n",
    "    if len(streets) == 0:\n",
    "        street = None\n",
    "    else:\n",
    "        street = streets[0]\n",
    "    town = [p for p in priority if p != street and x[p] == 1]\n",
    "    town = town[0] if len(town) > 0 else None\n",
    "    leftover = [\n",
    "        x for x in streets\n",
    "        if x != street\n",
    "        and x != town\n",
    "        and x not in ['1', '2', '3']\n",
    "    ]\n",
    "    muni = [x for x in streets if x in ['2', '3']]\n",
    "\n",
    "    return street, town, leftover, muni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "laAYHK87xAQB"
   },
   "source": [
    "# Core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvy2nYLwxjrU"
   },
   "source": [
    "## Define Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "22ZKvqL5w7Ba"
   },
   "outputs": [],
   "source": [
    "regions = glob.glob('data/[0-9][0-9]')\n",
    "region = regions[0]\n",
    "region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WuYzxicYxc14"
   },
   "source": [
    "## Read Address Object File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K4-4guZbxHOB"
   },
   "outputs": [],
   "source": [
    "fname = glob.glob(os.path.join(region, 'AS_ADDR_OBJ_*.XML'))\n",
    "fname = [x for x in fname if 'PARAMS' not in x and 'DIVISION' not in x]\n",
    "if len(fname) != 1:\n",
    "    msg = f'Please check file count for region {region} there are {len(fname)} files'\n",
    "    logger.error(msg)\n",
    "    raise Exception(msg)\n",
    "fname = fname[0]\n",
    "adobj = parse_xml(fname)\n",
    "adobj = adobj[(adobj['ISACTUAL'] == '1') & (adobj['ISACTIVE'] == '1')]\n",
    "adobj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bUshQ7SHxrtm"
   },
   "outputs": [],
   "source": [
    "fname = glob.glob('data/AS_ADDR_OBJ_TYPES_*.XML')\n",
    "if len(fname) != 1:\n",
    "    msg = f'Please check file count for region {region} there are {len(fname)} files'\n",
    "    logger.error(msg)\n",
    "    raise Exception(msg)\n",
    "fname = fname[0]\n",
    "adobjt = parse_xml(fname)\n",
    "adobjt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VQ1n_m60zfy2"
   },
   "outputs": [],
   "source": [
    "adobj = adobj.merge(\n",
    "    adobjt[['SHORTNAME', 'DESC', 'LEVEL']].rename(\n",
    "        columns={\n",
    "            'SHORTNAME': 'TYPENAME',\n",
    "            'DESC': 'TYPELONGNAME'\n",
    "        }\n",
    "    ),\n",
    "    on=['LEVEL', 'TYPENAME']\n",
    ")\n",
    "cleanup(adobjt)\n",
    "adobj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gDzd_kGwxu6T"
   },
   "outputs": [],
   "source": [
    "fname = glob.glob('data/AS_OBJECT_LEVELS_*.XML')\n",
    "if len(fname) != 1:\n",
    "    msg = f'Please check file count for region {region} there are {len(fname)} files'\n",
    "    logger.error(msg)\n",
    "    raise Exception(msg)\n",
    "fname = fname[0]\n",
    "lev = parse_xml(fname)\n",
    "\n",
    "adobj = adobj.merge(\n",
    "    lev[['NAME', 'LEVEL']].rename(\n",
    "        columns={\n",
    "            'NAME': 'LEVELNAME'\n",
    "        }\n",
    "    ),\n",
    "    on='LEVEL'\n",
    ")\n",
    "adobj.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRAxo_2wyPSh"
   },
   "source": [
    "## Read Houses File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H08LaQMkyI8B"
   },
   "outputs": [],
   "source": [
    "fname = glob.glob(os.path.join(region, 'AS_HOUSES_*.XML'))\n",
    "fname = [x for x in fname if 'PARAMS' not in x]\n",
    "if len(fname) != 1:\n",
    "    msg = f'Please check file count for region {region} there are {len(fname)} files'\n",
    "    logger.error(msg)\n",
    "    raise Exception(msg)\n",
    "fname = fname[0]\n",
    "hous = parse_xml(fname)\n",
    "hous = hous.rename(\n",
    "    columns={\n",
    "        'ADDTYPE1': 'HOUSETYPE1',\n",
    "        'ADDTYPE2': 'HOUSETYPE2',\n",
    "        'ADDNUM1': 'HOUSENUM1',\n",
    "        'ADDNUM2': 'HOUSENUM2'\n",
    "    }\n",
    ")\n",
    "if 'ISACTUAL' in hous.columns:\n",
    "    hous = hous[(hous['ISACTUAL'] == '1') & (hous['ISACTIVE'] == '1')]\n",
    "else:\n",
    "    hous = hous[(hous['ISACTIVE'] == '1')]\n",
    "hous.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2lBV-l7nyXgv"
   },
   "outputs": [],
   "source": [
    "fname = glob.glob('data/AS_HOUSE_TYPES_*.XML')\n",
    "if len(fname) != 1:\n",
    "    msg = f'Please check file count for region {region} there are {len(fname)} files'\n",
    "    logger.error(msg)\n",
    "    raise Exception(msg)\n",
    "fname = fname[0]\n",
    "houst = parse_xml(fname)\n",
    "houst = houst.rename(\n",
    "    columns={\n",
    "        'SHORTNAME': 'TYPENAME',\n",
    "        'DESC': 'TYPELONGNAME',\n",
    "        'ID': 'HOUSETYPE'\n",
    "    }\n",
    ")\n",
    "houst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dr8i2Q7pyfka"
   },
   "outputs": [],
   "source": [
    "hous = hous.merge(\n",
    "    houst[[\n",
    "        'HOUSETYPE', 'TYPENAME', 'TYPELONGNAME'\n",
    "    ]].drop_duplicates(),\n",
    "    on='HOUSETYPE'\n",
    ")\n",
    "if 'HOUSETYPE2' in hous.columns:\n",
    "    hous = hous.merge(\n",
    "        houst[[\n",
    "            'HOUSETYPE', 'TYPENAME', 'TYPELONGNAME'\n",
    "        ]].rename(\n",
    "            columns={\n",
    "                'HOUSETYPE': 'HOUSETYPE1'\n",
    "            }\n",
    "        ).drop_duplicates(),\n",
    "        on='HOUSETYPE1',\n",
    "        how='left',\n",
    "        suffixes=(None, '1')\n",
    "    )\n",
    "else:\n",
    "    hous['HOUSETYPE1'] = np.nan\n",
    "    hous['TYPELONGNAME1'] = np.nan\n",
    "    hous['HOUSENUM1'] = np.nan\n",
    "    hous['TYPENAME1'] = np.nan\n",
    "if 'HOUSETYPE2' in hous.columns:\n",
    "    hous = hous.merge(\n",
    "        houst[[\n",
    "            'HOUSETYPE', 'TYPENAME', 'TYPELONGNAME'\n",
    "        ]].rename(\n",
    "            columns={\n",
    "                'HOUSETYPE': 'HOUSETYPE2'\n",
    "            }\n",
    "        ).drop_duplicates(),\n",
    "        on='HOUSETYPE2',\n",
    "        how='left',\n",
    "        suffixes=(None, '2')\n",
    "    )\n",
    "else:\n",
    "    hous['HOUSETYPE2'] = np.nan\n",
    "    hous['TYPELONGNAME2'] = np.nan\n",
    "    hous['HOUSENUM2'] = np.nan\n",
    "    hous['TYPENAME2'] = np.nan\n",
    "cleanup(houst)\n",
    "hous.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AcMDH6obyjWJ"
   },
   "outputs": [],
   "source": [
    "hous['LEVEL'] = '10'\n",
    "hous['LEVELNAME'] = 'Здание/Сооружение'\n",
    "hous['NAME'] = hous['TYPELONGNAME'].str.lower() + ' ' + \\\n",
    "    hous['HOUSENUM']\n",
    "hous['NAME1'] = hous[['TYPELONGNAME1', 'HOUSENUM1']].apply(\n",
    "    lambda x: x['TYPELONGNAME1'].lower() + ' ' + x['HOUSENUM1']\n",
    "    if x['HOUSENUM1'] == x['HOUSENUM1']\n",
    "    and x['TYPELONGNAME1'] == x['TYPELONGNAME1']\n",
    "    else '',\n",
    "    axis=1\n",
    ")\n",
    "hous['NAME2'] = hous[['TYPELONGNAME2', 'HOUSENUM2']].apply(\n",
    "    lambda x: x['TYPELONGNAME2'].lower() + ' ' + x['HOUSENUM2']\n",
    "    if x['HOUSENUM2'] == x['HOUSENUM2']\n",
    "    and x['TYPELONGNAME2'] == x['TYPELONGNAME2']\n",
    "    else '',\n",
    "    axis=1\n",
    ")\n",
    "hous.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eTVM5amLym4Q"
   },
   "outputs": [],
   "source": [
    "hadobj = pd.concat(\n",
    "  [\n",
    "      adobj[[\n",
    "          'OBJECTID', 'OBJECTGUID', 'NAME', 'TYPENAME', 'LEVEL',\n",
    "          'ISACTUAL', 'ISACTIVE', 'TYPELONGNAME', 'LEVELNAME'\n",
    "      ]],\n",
    "      hous[[\n",
    "          'OBJECTID', 'OBJECTGUID', 'HOUSENUM', 'HOUSETYPE',\n",
    "          'TYPENAME', 'TYPELONGNAME', 'HOUSENUM1', 'HOUSETYPE1',\n",
    "          'TYPENAME1', 'TYPELONGNAME1', 'HOUSENUM2', 'HOUSETYPE2',\n",
    "          'TYPENAME2', 'TYPELONGNAME2', 'ISACTUAL', 'ISACTIVE',\n",
    "          'LEVEL', 'NAME', 'NAME1', 'NAME2', 'LEVELNAME'\n",
    "      ]]\n",
    "  ],\n",
    "  sort=True,\n",
    "  ignore_index=True\n",
    ")\n",
    "cleanup(adobj)\n",
    "cleanup(hous)\n",
    "hadobj.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6KXFUVpiy0Ri"
   },
   "source": [
    "## Read Administrative Relations File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WeL_VySbyqDQ"
   },
   "outputs": [],
   "source": [
    "fname = glob.glob(os.path.join(region, 'AS_ADM_HIERARCHY_*.XML'))\n",
    "if len(fname) != 1:\n",
    "    msg = f'Please check file count for region {region} there are {len(fname)} files'\n",
    "    logger.error(msg)\n",
    "    raise Exception(msg)\n",
    "fname = fname[0]\n",
    "adm = parse_xml(fname)\n",
    "adm0 = adm[adm['ISACTIVE'] == '1'][['OBJECTID', 'PARENTOBJID']].merge(\n",
    "    hadobj[(hadobj['ISACTUAL'] == '1') & (hadobj['ISACTIVE'] == '1')],\n",
    "    on='OBJECTID'\n",
    ")\n",
    "cleanup(adm)\n",
    "adm0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEmsQtcvz8Ok"
   },
   "source": [
    "## Building Address Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6r3DX7_nzzss"
   },
   "outputs": [],
   "source": [
    "rdadm = get_adms(adm0)\n",
    "cleanup(adm0)\n",
    "[(k, v) for k, v in rdadm.items()][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D5-HjyLW0Cuz"
   },
   "outputs": [],
   "source": [
    "hadobjd = hadobj.set_index('OBJECTID').to_dict('index')\n",
    "chains = [\n",
    "    get_adms_rec_rev([x], rdadm)\n",
    "    for x in tqdm(hadobj[hadobj['LEVEL'] == '10']['OBJECTID'])\n",
    "]\n",
    "# save and clean\n",
    "hadobj.to_csv(f'{region}_hadobj.csv', index=False)\n",
    "cleanup(hadobj)\n",
    "[(k, v) for k, v in hadobjd.items()][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vLmRu58T0EWR"
   },
   "outputs": [],
   "source": [
    "dfch = pd.DataFrame()\n",
    "dfch['chain'] = [tuple(x) for x in chains]\n",
    "cleanup(chains)\n",
    "dfch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0fDB2gVGGNqa"
   },
   "outputs": [],
   "source": [
    "dfch['levchain'] = [\n",
    "    tuple([hadobjd[y]['LEVEL'] for y in x if y != '0' and y in hadobjd])\n",
    "    for x in tqdm(dfch['chain'])\n",
    "]\n",
    "dat = [\n",
    "    {\n",
    "        m: l\n",
    "        for m, l in zip(x, y)\n",
    "    }\n",
    "    for x, y in zip(dfch['levchain'], dfch['chain'])\n",
    "]\n",
    "for i in range(10, 0, -1):\n",
    "    dfch[f'{i}'] = [\n",
    "        d[f'{i}']\n",
    "        if f'{i}' in d\n",
    "        else None\n",
    "        for d in dat\n",
    "    ]\n",
    "dfch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "otcnWqPdGQ4T"
   },
   "outputs": [],
   "source": [
    "chl = list(set(dfch['levchain'].apply(lambda x: '-'.join(x))))\n",
    "df = pd.DataFrame()\n",
    "df['levchain'] = chl\n",
    "for i in range(10, 0, -1):\n",
    "    dat = [(f'{i}' in y.split('-')) * 1 for y in chl]\n",
    "    df[f'{i}'] = dat\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uy6hKMVOGUPJ"
   },
   "outputs": [],
   "source": [
    "lst = df.apply(get_town, axis=1)\n",
    "df['street'] = [x[0] for x in lst]\n",
    "df['town'] = [x[1] for x in lst]\n",
    "df['leftover'] = [x[2] for x in lst]\n",
    "df['muni'] = [x[3] for x in lst]\n",
    "df['levchain'] = df['levchain'].apply(lambda x: tuple(x.split('-')))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oDTRvlqhGXEj"
   },
   "outputs": [],
   "source": [
    "dfch = dfch.merge(df[['levchain', 'street', 'town', 'leftover', 'muni']], on='levchain')\n",
    "dfch['region'] = region\n",
    "dfch.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tXHpsloGlhh"
   },
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ySj71rvjGaip"
   },
   "outputs": [],
   "source": [
    "dfch.to_csv(f'{region}_parsed_chains.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZ-MflHpHFj0"
   },
   "source": [
    "# Read Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zIfVLYlBGqAH"
   },
   "outputs": [],
   "source": [
    "# replace with your path\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\", force_remount=True)\n",
    "%cd \"drive/MyDrive/gar_colab/garbdfias\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WC-fygmJHIHK"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m9fZqgYxHLFT"
   },
   "outputs": [],
   "source": [
    "regions = glob.glob('data/[0-9][0-9]')\n",
    "region = regions[0]\n",
    "region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dwuJP6WrHNoL"
   },
   "outputs": [],
   "source": [
    "hadobj = pd.read_csv(f'{region}_hadobj.csv')\n",
    "hadobj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CpduY0zlHSs8"
   },
   "outputs": [],
   "source": [
    "hadobj.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v3ltio4THTU9"
   },
   "outputs": [],
   "source": [
    "hadobj.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2yKjXrdXHjZ7"
   },
   "outputs": [],
   "source": [
    "for x in [\n",
    "          'OBJECTID', 'HOUSENUM', 'HOUSENUM1',\n",
    "          'HOUSENUM2', 'LEVEL', 'NAME',\n",
    "          'TYPELONGNAME', 'TYPELONGNAME1', 'TYPELONGNAME2',\n",
    "          'TYPENAME', 'TYPENAME1', 'TYPENAME2']:\n",
    "    hadobj[x] = hadobj[x].apply(lambda y: str(y) if y == y else np.nan)\n",
    "hadobj['OBJECTID'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9IZEpABlHoeU"
   },
   "outputs": [],
   "source": [
    "dfch = pd.read_csv(f'{region}_parsed_chains.csv')\n",
    "dfch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0dkdX12Hsp6"
   },
   "outputs": [],
   "source": [
    "for x in ['chain', 'levchain', 'leftover', 'muni']:\n",
    "    dfch[x] = [literal_eval(y) for y in tqdm(dfch[x])]\n",
    "for x in range(1, 11, 1):\n",
    "    dfch[f'{x}'] = dfch[f'{x}'].astype(str).apply(lambda y: y.split('.')[0] if y == y else y)\n",
    "    dfch[f'{x}'] = dfch[f'{x}'].apply(lambda y: y if y != '' else np.nan)\n",
    "for x in ['street', 'town', 'region']:\n",
    "    dfch[x] = dfch[x].astype(str).apply(lambda y: y.split('.')[0] if y == y else y)\n",
    "    dfch[x] = dfch[x].apply(lambda y: y if y != '' else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kiqT9WpjHv--"
   },
   "outputs": [],
   "source": [
    "dfch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sH3IfipKHy2a"
   },
   "outputs": [],
   "source": [
    "hadobjd = hadobj.set_index('OBJECTID').to_dict('index')\n",
    "[(k, v) for k, v in hadobjd.items()][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJfU_xFUH7Ms"
   },
   "source": [
    "## Plaintext Addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KF5ZinS7H22n"
   },
   "outputs": [],
   "source": [
    "addresses = {x[0]: [] for x in tqdm(dfch.chain)}\n",
    "for x in tqdm(dfch.chain):\n",
    "    for y in x:\n",
    "        if y != '0':\n",
    "            addresses[x[0]].append(hadobjd[y]['TYPELONGNAME'])\n",
    "            if hadobjd[y]['LEVEL'] != '10':\n",
    "                addresses[x[0]].append(hadobjd[y]['NAME'])\n",
    "            else:\n",
    "                addresses[x[0]].append(hadobjd[y]['HOUSENUM'])\n",
    "                if hadobjd[y]['HOUSENUM1'] == hadobjd[y]['HOUSENUM1']:\n",
    "                    addresses[x[0]].append(hadobjd[y]['TYPELONGNAME1'])\n",
    "                    addresses[x[0]].append(hadobjd[y]['HOUSENUM1'])\n",
    "                    if hadobjd[y]['HOUSENUM2'] == hadobjd[y]['HOUSENUM2']:\n",
    "                        addresses[x[0]].append(hadobjd[y]['TYPELONGNAME2'])\n",
    "                        addresses[x[0]].append(hadobjd[y]['HOUSENUM2'])\n",
    "addresses = {k: ' '.join(v) for k, v in addresses.items()}\n",
    "sample = random.sample(addresses.keys(), 10)\n",
    "{s: addresses[s].lower() for s in sample}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jz0JEPKjIFUP"
   },
   "source": [
    "## Structured Addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4lloG-ewH-z-"
   },
   "outputs": [],
   "source": [
    "def get_struct_addr(x):\n",
    "    town = hadobjd[x[x['town']]]\n",
    "    town = town['TYPELONGNAME'] + ' ' + town['NAME']\n",
    "    street = hadobjd[x[x['street']]]\n",
    "    street = street['TYPELONGNAME'] + ' ' + street['NAME']\n",
    "    house = hadobjd[x['10']]\n",
    "    house0 = house['TYPELONGNAME'] + ' ' + house['HOUSENUM']\n",
    "    house1 = ''\n",
    "    house2 = ''\n",
    "    if house['HOUSENUM1'] == house['HOUSENUM1']:\n",
    "        house1 = house['TYPELONGNAME1'] + ' ' + house['HOUSENUM1']\n",
    "    if house['HOUSENUM2'] == house['HOUSENUM2']:\n",
    "        house2 = house['TYPELONGNAME2'] + ' ' + house['HOUSENUM2']\n",
    "    leftover = []\n",
    "    for y in x['leftover']:\n",
    "        leftover.append(hadobjd[x[y]]['TYPELONGNAME'])\n",
    "        leftover.append(hadobjd[x[y]]['NAME'])\n",
    "    leftover = ' '.join(leftover)\n",
    "    muni = []\n",
    "    for y in x['muni']:\n",
    "        muni.append(hadobjd[x[y]]['TYPELONGNAME'])\n",
    "        muni.append(hadobjd[x[y]]['NAME'])\n",
    "    muni = ' '.join(muni)\n",
    "    return {\n",
    "        'town': town,\n",
    "        'street': street,\n",
    "        'house': house0,\n",
    "        'house1': house1,\n",
    "        'house2': house2,\n",
    "        'leftover': leftover,\n",
    "        'muni': muni\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KBxdLGYFIJVc"
   },
   "outputs": [],
   "source": [
    "struct_addresses = dfch.apply(get_struct_addr, axis=1)\n",
    "struct_addresses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JAjIo1-FILhk"
   },
   "outputs": [],
   "source": [
    "structdf = pd.DataFrame.from_records(struct_addresses)\n",
    "structdf.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fe-hbxw3IQro"
   },
   "outputs": [],
   "source": [
    "grouped = structdf.groupby(by=['town', 'street', 'house', 'house1', 'house2']).aggregate(lambda x: x.to_list())\n",
    "grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p2gBGA3PIVHV"
   },
   "outputs": [],
   "source": [
    "grouped[grouped['muni'].apply(lambda x: len(x) > 1)].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k701t6t1IdKQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GAR16.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
